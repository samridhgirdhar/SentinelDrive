# SentinelDrive ğŸš—ğŸ’¡ â€“ The Ultimate AIâ€‘Powered Driver Safety Suite

> **â€œEnhancing human reflexes with silicon instincts.â€**

![SentinelDrive Banner](media/4.mp4)

[![Build](https://img.shields.io/github/actions/workflow/status/yourâ€‘org/sentineldrive/ci.yml?style=flat-square)](â€¦)
[![License](https://img.shields.io/github/license/yourâ€‘org/sentineldrive?style=flat-square)](LICENSE)
[![PythonÂ 3.11](https://img.shields.io/badge/python-3.11+-blue.svg?logo=python\&style=flat-square)](https://www.python.org/)
[![ArduinoÂ Nano](https://img.shields.io/badge/hardware-arduino%20nano-green?style=flat-square\&logo=arduino)](https://www.arduino.cc/)

---

## âœ¨ TL;DR

SentinelDrive fuses **Computerâ€‘Vision steering analysis**, **ultrasonic blindâ€‘spot detection**, and a **voiceâ€‘activated AI coâ€‘pilot (Sheero)** into a single openâ€‘source stack.  It watches the road, senses obstacles, keeps an eye on driver wellâ€‘being, *and* chats back using a local LLM â€“ all in <Â 80Â W on a RaspberryÂ PiÂ 5 + Arduino Nano.

<table>
<tr><th align="center">ğŸ‘ï¸ CV_SafetySuite</th><th align="center">ğŸ”Š Sheero AI Assistant</th><th align="center">ğŸ“¡ Arduino Blindâ€‘Spot Module</th></tr>
<tr><td valign="top"><ul><li>Drowsiness, drunk, stress & steering detection</li><li>Realâ€‘time <code>&lt;35Â ms</code> inference on PiÂ GPU</li><li>EAR, headâ€‘pose &amp; HSV tracking pipelines</li></ul></td><td valign="top"><ul><li>Wakeâ€‘word â€œgogiâ€ + fast Vosk ASR</li><li>Contextâ€‘aware tips via local <strong>Mistralâ€‘7B</strong></li><li>Glowing Web dashboard with animations</li></ul></td><td valign="top"><ul><li>4Ã— HCâ€‘SR04 ultrasonic sensors per flank</li><li>&lt;100Â cm proximity buzzer alerts</li><li>CANâ€‘Busâ€‘style serial to Pi controller</li></ul></td></tr>
</table>

![Demo GIF](docs/assets/demo.gif)

---

## ğŸ“š TableÂ ofÂ Contents

1. [Features](#features)
2. [Architecture](#architecture)
3. [QuickÂ Start](#quick-start)
4. [DirectoryÂ Layout](#directory-layout)
5. [Roadmap](#roadmap)
6. [Contributing](#contributing)
7. [License](#license)

---

## ğŸš€ Features <a name="features"></a>

### 1. Computerâ€‘Vision Safety Suite

* **Steering intent** via colourâ€‘tracked steeringâ€‘wheel markers.
* **Drowsiness** (EARÂ <Â 0.18 forÂ >2â€¯s) & **headâ€‘bow shake**Â >60â€¯px detect fatigue or impairment.
* **Stress cues** captured with Vosk keyword spotting & amplitude spikes.
* Modular OpenCV pipeline â€“ runs as a ROSÂ 2 node.

### 2. Blindâ€‘Spot Sentinel

* Dual flanks instrumented with **4Ã— HCâ€‘SR04** sensors scanning everyÂ 500â€¯ms.
* Turnâ€‘signal + distanceÂ <100â€¯cm â†’ *directional* buzzer.  Falseâ€‘positives squashed by conjunctive logic.

### 3. Sheero â€“ Voice AI Coâ€‘Pilot

* Handsâ€‘free wakeâ€‘word **â€œgogiâ€** and 10â€¯s naturalâ€‘language command window.
* Local **Mistral** model (via [Ollama](https://github.com/jmorganca/ollama)) serves hyperâ€‘concise driving advice.
* FlaskÂ +Â WebSocket dashboard with live wave/orbit/pulse animations & alert LEDs.
* Safetyâ€‘first prompt engineering ensures *<20â€‘word* actionable cues.

---

## ğŸ§© Architecture <a name="architecture"></a>

```mermaid
flowchart TD
    %% Edge Device block
    subgraph EDGE_DEVICE["Edge Device<br/>(Raspberry Pi 5)"]
        CV["CV_SafetySuite (service)"]
        VA["Sheero Flask server"]
    end

    %% Arduino block
    subgraph ARDUINO["Arduino Nano"]
        US["4Ã— Ultrasonic"]
        Buzz["Buzzer L/R"]
    end

    %% Interâ€‘module links
    CV -- "JSON alerts" --> VA
    US -- "Serial UART" --> CV
    CV -- "GPIO pins" --> Buzz

    %% Styling
    style Buzz fill:#ffd2d2,color:#000
```

---

## âš¡ï¸ QuickÂ Start <a name="quick-start"></a>

```bash
# 1) Clone & submodules
$ git clone https://github.com/yourâ€‘org/sentineldrive.git && cd sentineldrive

# 2) Python env
$ python3 -m venv .venv && source .venv/bin/activate
$ pip install -r requirements.txt  # OpenCV, Vosk, gTTS, Pygame, Flaskâ€¦

# 3) Install Ollama + pull local model
$ curl https://ollama.ai/install.sh | sh
$ ollama pull mistral

# 4) Flash the Arduino sketch (see firmware/)
$ arduino-cli upload -p /dev/ttyUSB0 -b arduino:avr:nano firmware/blindspot.ino

# 5) Run everything
$ python src/VoiceAssistant.py  # spawns CV & dashboard workers automatically
```

> **Tip:** For headless operation, use `tmuxp load dev.tmuxp.yaml`.

---

## ğŸ—‚ Directory Layout <a name="directory-layout"></a>

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ CV_SafetySuite.ipynb   # Jupyter prototype â€“ convert to .py for prod
â”‚   â”œâ”€â”€ VoiceAssistant.py      # Sheero AI assistant
â”‚   â””â”€â”€ modules/              # Reusable OpenCV & signal helpers
â”œâ”€â”€ firmware/
â”‚   â””â”€â”€ blindspot.ino         # Arduino Nano sketch
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ assets/               # Diagrams, banners, demo GIFs
â”‚   â””â”€â”€ SentinelDrive.pdf     # Full project writeâ€‘up / slides
â””â”€â”€ tests/                    # PyTestâ€‘powered CICD smoke tests
```

---

## ğŸ—º Roadmap <a name="roadmap"></a>

* [ ] Replace HSV steering detection with **MediaPipe Hands**.
* [ ] Integrate **LiDAR** for rear crossâ€‘traffic.
* [ ] Migrate from Vosk to **Whisper.cpp** for multilingual commands.
* [ ] OTA updates via **Fly.io** edgeâ€‘deployments.

---

## ğŸ¤ Contributing <a name="contributing"></a>

1. ForkÂ âœ Feature branchÂ âœ PR (with screenshot/GIF).
2. Run `preâ€‘commit run â€‘â€‘all-files` (black, isort, ruff).
3. Describe *why* not just *what* in commit body.

### Ground Rules

* **No distractions:** The assistant must never encourage risky behaviour.
* **Edge safety first:** Ship failsafes before fancy features.

---

## ğŸ“œ License <a name="license"></a>

Licensed under the **MIT License** â€“ see [`LICENSE`](LICENSE) for details.

---

## ğŸ™ Acknowledgements

* Project concept & PDF slides by **GroupÂ 2, IITâ€‘Delhi**.
* Inâ€‘car footage & datasets contributed by community testers.
* Inspired by Tesla Autopilot UI and GM Super Cruise HUD.

<div align="center">
   <sub>Made with â¤ï¸Â & caffeine on NHâ€‘48.</sub>
</div>
