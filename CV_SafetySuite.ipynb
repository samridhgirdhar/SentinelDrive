{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c539d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp311-cp311-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Collecting vosk\n",
      "  Using cached vosk-0.3.44-py3-none-macosx_10_6_universal2.whl.metadata (1.8 kB)\n",
      "Collecting sounddevice\n",
      "  Using cached sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: playsound in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (24.3.25)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (3.8.3)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (4.25.3)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from vosk) (1.17.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from vosk) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from vosk) (4.67.1)\n",
      "Collecting srt (from vosk)\n",
      "  Using cached srt-3.5.3.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting websockets (from vosk)\n",
      "  Using cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=1.0->vosk) (2.22)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Requirement already satisfied: opt_einsum in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kanishk/Library/Python/3.11/lib/python/site-packages (from matplotlib->mediapipe) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kanishk/Library/Python/3.11/lib/python/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vosk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vosk) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vosk) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vosk) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kanishk/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.21-cp311-cp311-macosx_11_0_universal2.whl (49.2 MB)\n",
      "Using cached vosk-0.3.44-py3-none-macosx_10_6_universal2.whl (4.7 MB)\n",
      "Using cached sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Using cached jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "Downloading jaxlib-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (53.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (46.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.4/671.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: srt\n",
      "  Building wheel for srt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=d81c909fe04d611d3ce03f0e1721728d2428d420a89c70febc43ab1a4d475a38\n",
      "  Stored in directory: /Users/kanishk/Library/Caches/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
      "Successfully built srt\n",
      "Installing collected packages: sentencepiece, websockets, srt, opencv-contrib-python, ml_dtypes, vosk, sounddevice, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: ml_dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jax-0.6.0 jaxlib-0.6.0 mediapipe-0.10.21 ml_dtypes-0.5.1 opencv-contrib-python-4.11.0.86 sentencepiece-0.2.0 sounddevice-0.5.1 srt-3.5.3 vosk-0.3.44 websockets-15.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe vosk sounddevice scipy opencv-python numpy playsound\n",
    "# Download a Vosk English model (40 MB) once:\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcfa462",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mDriver Safety Suite (final)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m--------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mQ      – quit\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mthreading\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mqueue\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msubprocess\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaysound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m playsound\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m framework\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gpu\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/audio/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks Audio API.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classifier\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_embedder\u001b[39;00m\n\u001b[1;32m     21\u001b[0m AudioClassifier \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifier\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/audio/audio_classifier.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier_options_pb2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_task_running_mode \u001b[38;5;28;01mas\u001b[39;00m running_mode_module\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_audio_task_api\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_data \u001b[38;5;28;01mas\u001b[39;00m audio_data_module\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_result \u001b[38;5;28;01mas\u001b[39;00m classification_result_module\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/audio/core/base_audio_task_api.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_record\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_task_running_mode \u001b[38;5;28;01mas\u001b[39;00m running_mode_module\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptional_dependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_controls\n\u001b[1;32m     27\u001b[0m _TaskRunner \u001b[38;5;241m=\u001b[39m task_runner_module\u001b[38;5;241m.\u001b[39mTaskRunner\n\u001b[1;32m     28\u001b[0m _Packet \u001b[38;5;241m=\u001b[39m packet_module\u001b[38;5;241m.\u001b[39mPacket\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/core/optional_dependencies.py:20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# TensorFlow isn't a dependency of mediapipe pip package. It's only\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# required in the API docgen pipeline so we'll ignore it if tensorflow is not\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# installed.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_controls\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m# Replace the real doc_controls.do_not_generate_docs with an no-op\u001b[39;00m\n\u001b[1;32m     23\u001b[0m   doc_controls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/__init__.py:462\u001b[0m\n\u001b[1;32m    460\u001b[0m     importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras.src.optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.src.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    464\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _tf_keras\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/_tf_keras/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/_tf_keras/keras/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/activations/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/activations/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tanh\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n\u001b[1;32m     25\u001b[0m ALL_OBJECTS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     26\u001b[0m     relu,\n\u001b[1;32m     27\u001b[0m     leaky_relu,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     log_softmax,\n\u001b[1;32m     44\u001b[0m }\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_registered_object\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_keras_serializable\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m legacy_h5_format\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_utils\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_utils\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_options\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _build_map\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/model.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_api\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trainer \u001b[38;5;28;01mas\u001b[39;00m base_trainer\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary_utils\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/trainer.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompileLoss\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompileMetrics\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter_utils\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m traceback_utils\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracking\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/data_adapters/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribution_lib\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_data_adapter\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m py_dataset_adapter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_data_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayDataAdapter\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_slicing\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter_utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataAdapter\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_slicing.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     pandas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/__init__.py:119\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m offsets\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    122\u001b[0m     concat,\n\u001b[1;32m    123\u001b[0m     lreshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     qcut,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/computation/api.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/computation/eval.py:15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_bool_kwarg\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_extension_array_dtype\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ENGINES\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     PARSERS,\n\u001b[1;32m     18\u001b[0m     Expr,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenize_string\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Driver Safety Suite (final)\n",
    "--------------------------------\n",
    "* Steering direction (green sticker)\n",
    "* Drowsiness (eyes closed > 2 s)\n",
    "* Drunk / unwell  – head bowed > 1.5 s **or** shake RMS > 60 px sustained ≥ 3 s\n",
    "* Stress – shouting > 2 s **or** keywords \"FUCK\", \"MOVE ASIDE\" (offline ASR)\n",
    "\n",
    "Controls\n",
    "========\n",
    "SPACE  – calibrate steering centre\n",
    "S      - manually trigger stress (test)\n",
    "B      - test beep sound\n",
    "Q      – quit\n",
    "\"\"\"\n",
    "\n",
    "import cv2, mediapipe as mp, numpy as np, time, threading, queue, json, collections, subprocess, os, sys\n",
    "import sounddevice as sd\n",
    "from playsound import playsound\n",
    "try:\n",
    "    from vosk import Model, KaldiRecognizer\n",
    "    VOSK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: Vosk speech recognition not available\")\n",
    "    VOSK_AVAILABLE = False\n",
    "\n",
    "# ---------------------------- CONFIG ------------------------------------\n",
    "LOWER = np.array([40,  80,  80])      # HSV range for neon‑green sticker\n",
    "UPPER = np.array([85, 255, 255])\n",
    "STEER_DEAD_PX    = 60                 # half‑width of steering dead‑zone (px)\n",
    "STEER_FRAMES_REQ = 4                  # frames beyond dead‑zone before state flips\n",
    "\n",
    "EAR_TH        = 0.18                  # eye‑aspect‑ratio threshold\n",
    "DROWSY_SEC    = 2.0\n",
    "\n",
    "BOW_SEC       = 1.5\n",
    "SHAKE_RMS_PX  = 60\n",
    "SHAKE_SEC     = 3.0\n",
    "\n",
    "# Substantially lower thresholds for stress detection\n",
    "SHOUT_GAIN    = 10.0                   # Volume threshold multiplier\n",
    "SHOUT_SEC     = 1.0                   # Seconds required for shouting\n",
    "STRESS_DISPLAY_SEC = 5.0              # How long to display the stress warning\n",
    "\n",
    "KW_SET        = {\"FUCK\"}              # Individual keywords\n",
    "KW_PHRASES    = [\"MOVE ASIDE\"]        # Phrases to detect\n",
    "\n",
    "AUDIO_BLOCK   = 0.5                   # Half-second blocks for quicker response\n",
    "BEEP_PATH     = \"/Users/samridhgirdhar/Downloads/beep2.mp3\"            # Default beep sound\n",
    "MODEL_DIR     = \"vosk_en\"             # path to Vosk EN model directory\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------- HELPERS -----------------------------------\n",
    "mp_face = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "LIDS_L  = [33,160,158,133,153,144]\n",
    "LIDS_R  = [362,385,387,263,373,380]\n",
    "\n",
    "def find_blob(mask):\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    M = cv2.moments(c)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return None\n",
    "    return int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "def ear(pts, idx):\n",
    "    \"\"\"Compute eye‑aspect‑ratio for given 6‑point lid indices.\"\"\"\n",
    "    p2p6 = np.linalg.norm(pts[idx[1]] - pts[idx[5]])\n",
    "    p3p5 = np.linalg.norm(pts[idx[2]] - pts[idx[4]])\n",
    "    p1p4 = np.linalg.norm(pts[idx[0]] - pts[idx[3]])\n",
    "    return (p2p6 + p3p5) / (2.0 * p1p4)\n",
    "\n",
    "def play_beep():\n",
    "    \"\"\"Simple beep function that works across platforms.\"\"\"\n",
    "    print(\"\\a\", end=\"\", flush=True)  # System bell as default\n",
    "    \n",
    "    try:\n",
    "        # Use platform-specific commands for more reliable sound\n",
    "        if sys.platform == 'win32':\n",
    "            import winsound\n",
    "            winsound.Beep(1000, 500)\n",
    "        elif sys.platform == 'darwin':  # macOS\n",
    "            subprocess.run(['afplay', '/System/Library/Sounds/Tink.aiff'], \n",
    "                          check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        elif sys.platform == 'linux':\n",
    "            subprocess.run(['paplay', '/usr/share/sounds/freedesktop/stereo/complete.oga'],\n",
    "                          check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    except Exception:\n",
    "        pass  # Fallback to system bell already done\n",
    "\n",
    "# ----------------------- AUDIO / STRESS DETECTION --------------------------\n",
    "\n",
    "def setup_vosk(sample_rate=16000):\n",
    "    \"\"\"Set up Vosk speech recognition if available.\"\"\"\n",
    "    if not VOSK_AVAILABLE:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        model = Model(MODEL_DIR) \n",
    "        return KaldiRecognizer(model, sample_rate)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR setting up Vosk: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_audio(stress_callback):\n",
    "    \"\"\"Process audio in a separate thread and detect stress via shouting or keywords.\"\"\"\n",
    "    fs = 16000\n",
    "    \n",
    "    # Try to set up speech recognition\n",
    "    recognizer = setup_vosk(fs)\n",
    "    speech_recognition = recognizer is not None\n",
    "    \n",
    "    print(f\"Audio processing thread started. Speech recognition: {speech_recognition}\")\n",
    "    \n",
    "    # Energy tracking variables\n",
    "    audio_energies = collections.deque(maxlen=20)  # ~10 seconds history\n",
    "    high_energy_start = None\n",
    "    baseline_multiplier = 1.0  # Start with normal sensitivity\n",
    "    \n",
    "    # Initial baseline calculation period\n",
    "    print(\"Calculating audio baseline... please stay quiet\")\n",
    "    for _ in range(5):  # ~2.5 seconds to establish baseline\n",
    "        audio = sd.rec(int(AUDIO_BLOCK * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "        sd.wait()\n",
    "        block = audio.flatten()\n",
    "        energy = np.sqrt(np.mean(block ** 2))\n",
    "        audio_energies.append(energy)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    baseline_energy = np.mean(audio_energies) * 1.2  # Add 20% margin\n",
    "    print(f\"Audio baseline established: {baseline_energy:.6f}\")\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Record audio\n",
    "            audio = sd.rec(int(AUDIO_BLOCK * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "            sd.wait()\n",
    "            block = audio.flatten()\n",
    "            \n",
    "            # Calculate energy and update rolling history\n",
    "            energy = np.sqrt(np.mean(block ** 2))\n",
    "            audio_energies.append(energy)\n",
    "            \n",
    "            # Gradually update baseline to adapt to environment\n",
    "            if len(audio_energies) >= 10:  # Wait for enough history\n",
    "                # Use the 20th percentile as the baseline for better stability\n",
    "                sorted_energies = sorted(audio_energies)\n",
    "                baseline_energy = sorted_energies[int(len(sorted_energies) * 0.2)]\n",
    "            \n",
    "            # Print energy levels occasionally for debugging\n",
    "            if np.random.random() < 0.05:  # ~5% of blocks\n",
    "                energy_ratio = energy / baseline_energy\n",
    "                print(f\"Audio: energy={energy:.6f}, baseline={baseline_energy:.6f}, ratio={energy_ratio:.2f}\")\n",
    "            \n",
    "            # Shouting detection\n",
    "            if energy > baseline_energy * SHOUT_GAIN * baseline_multiplier:\n",
    "                if high_energy_start is None:\n",
    "                    high_energy_start = time.time()\n",
    "                    print(f\"High volume detected! Ratio: {energy/baseline_energy:.2f}\")\n",
    "            else:\n",
    "                high_energy_start = None\n",
    "            \n",
    "            # If high energy sustains long enough, trigger stress\n",
    "            if high_energy_start and (time.time() - high_energy_start) >= SHOUT_SEC:\n",
    "                print(\"STRESS DETECTED: SHOUTING\")\n",
    "                stress_callback()\n",
    "                high_energy_start = None\n",
    "                # Temporarily increase sensitivity for next few seconds\n",
    "                baseline_multiplier = 0.8\n",
    "                time.sleep(1.0)  # Pause briefly to avoid rapid retriggers\n",
    "                continue\n",
    "            \n",
    "            # Restore normal sensitivity over time\n",
    "            baseline_multiplier = min(1.0, baseline_multiplier + 0.01)\n",
    "            \n",
    "            # Speech recognition for keywords\n",
    "            if speech_recognition:\n",
    "                # Convert float32 → int16 PCM for Vosk\n",
    "                block_int16 = (block * 32767).astype(np.int16).tobytes()\n",
    "                \n",
    "                if recognizer.AcceptWaveform(block_int16):\n",
    "                    result = json.loads(recognizer.Result())\n",
    "                    transcript = result.get(\"text\", \"\").upper()\n",
    "                    \n",
    "                    if transcript:\n",
    "                        print(f\"Speech: {transcript}\")\n",
    "                        \n",
    "                        # Check for keywords\n",
    "                        found_keywords = [w for w in transcript.split() if w in KW_SET]\n",
    "                        \n",
    "                        # Check for phrases\n",
    "                        found_phrases = [p for p in KW_PHRASES if p in transcript]\n",
    "                        \n",
    "                        if found_keywords:\n",
    "                            print(f\"STRESS DETECTED: Keywords {found_keywords}\")\n",
    "                            stress_callback()\n",
    "                        \n",
    "                        if found_phrases:\n",
    "                            print(f\"STRESS DETECTED: Phrase {found_phrases}\")\n",
    "                            stress_callback()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Audio error: {e}\")\n",
    "            time.sleep(1)  # Avoid error spam\n",
    "\n",
    "# ----------------------------- MAIN -------------------------------------\n",
    "\n",
    "def main(cam_index: int = 0):\n",
    "    try:\n",
    "        # Initialize camera\n",
    "        cap = cv2.VideoCapture(cam_index)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Camera not found - trying default camera\")\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            if not cap.isOpened():\n",
    "                raise RuntimeError(\"No cameras found - please connect a webcam or enable camera access\")\n",
    "\n",
    "        # ------- steering state -------\n",
    "        cx0 = None\n",
    "        steer_state = \"STRAIGHT\"\n",
    "        consecutive_lr = 0\n",
    "\n",
    "        # ------- timers & buffers -------\n",
    "        eye_closed_start = None\n",
    "        head_bow_start   = None\n",
    "        shake_start      = None\n",
    "        shake_buf        = collections.deque(maxlen=30)  # ≈1 s at 30 fps\n",
    "        last_beep = 0\n",
    "        \n",
    "        # ------- stress state -------\n",
    "        stressed = False\n",
    "        stress_end_time = 0\n",
    "        \n",
    "        def trigger_stress():\n",
    "            nonlocal stressed, stress_end_time\n",
    "            stressed = True\n",
    "            stress_end_time = time.time() + STRESS_DISPLAY_SEC\n",
    "            play_beep()\n",
    "        \n",
    "        # Start audio processing in background thread\n",
    "        audio_thread = threading.Thread(\n",
    "            target=process_audio,\n",
    "            args=(trigger_stress,),\n",
    "            daemon=True\n",
    "        )\n",
    "        audio_thread.start()\n",
    "\n",
    "        # Wait a moment for audio thread to initialize\n",
    "        time.sleep(2)\n",
    "        print(\"Driver Safety Suite started. Press SPACE to calibrate steering, Q to quit.\")\n",
    "\n",
    "        with mp_face.FaceMesh(max_num_faces=1, refine_landmarks=True,\n",
    "                            min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh, \\\n",
    "            mp_pose.Pose(static_image_mode=False) as pose:\n",
    "            \n",
    "            while True:\n",
    "                # Get frame from camera\n",
    "                ok, frame = cap.read()\n",
    "                if not ok:\n",
    "                    print(\"Camera read failed\")\n",
    "                    break\n",
    "                \n",
    "                h, w = frame.shape[:2]\n",
    "                \n",
    "                # Reset stress flag if timeout elapsed\n",
    "                if stressed and time.time() > stress_end_time:\n",
    "                    stressed = False\n",
    "\n",
    "                # ================== Steering detection ==================\n",
    "                hsv  = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                mask = cv2.inRange(hsv, LOWER, UPPER)\n",
    "                mask = cv2.erode(mask, None, 2)\n",
    "                mask = cv2.dilate(mask, None, 2)\n",
    "                blob = find_blob(mask)\n",
    "\n",
    "                if blob and cx0 is not None:\n",
    "                    dx = blob[0] - cx0\n",
    "                    if abs(dx) > STEER_DEAD_PX:\n",
    "                        consecutive_lr += 1\n",
    "                        if consecutive_lr >= STEER_FRAMES_REQ:\n",
    "                            steer_state = \"LEFT\" if dx < 0 else \"RIGHT\"\n",
    "                            consecutive_lr = STEER_FRAMES_REQ\n",
    "                    else:\n",
    "                        consecutive_lr = 0\n",
    "                        steer_state = \"STRAIGHT\"\n",
    "                elif not blob:\n",
    "                    steer_state = \"STKR MISS\"\n",
    "                else:\n",
    "                    steer_state = \"UN CAL\"\n",
    "\n",
    "                cv2.putText(frame, steer_state, (20, 60), cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "                # ================== Face & pose landmarks ==================\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                face_res = face_mesh.process(rgb)\n",
    "                pose_res = pose.process(rgb)\n",
    "\n",
    "                drowsy = False\n",
    "                drunk  = False\n",
    "\n",
    "                # ---------- drowsiness via eyes ----------\n",
    "                if face_res.multi_face_landmarks:\n",
    "                    pts = np.array([(p.x * w, p.y * h) for p in face_res.multi_face_landmarks[0].landmark])\n",
    "                    ear_now = (ear(pts, LIDS_L) + ear(pts, LIDS_R)) / 2\n",
    "\n",
    "                    if ear_now < EAR_TH:\n",
    "                        eye_closed_start = eye_closed_start or time.time()\n",
    "                    else:\n",
    "                        eye_closed_start = None\n",
    "\n",
    "                    if eye_closed_start and time.time() - eye_closed_start >= DROWSY_SEC:\n",
    "                        drowsy = True\n",
    "\n",
    "                    # ---------- head bow ----------\n",
    "                    eye_y  = pts[1][1]\n",
    "                    chin_y = pts[152][1]\n",
    "                    bowed = (eye_y - chin_y) > 40\n",
    "                    if bowed:\n",
    "                        head_bow_start = head_bow_start or time.time()\n",
    "                    else:\n",
    "                        head_bow_start = None\n",
    "                    if head_bow_start and time.time() - head_bow_start >= BOW_SEC:\n",
    "                        drunk = True\n",
    "\n",
    "                # ---------- shake detection ----------\n",
    "                if pose_res.pose_landmarks:\n",
    "                    nose_x = pose_res.pose_landmarks.landmark[0].x * w\n",
    "                    shake_buf.append(nose_x)\n",
    "                    if len(shake_buf) == shake_buf.maxlen:\n",
    "                        rms = np.std(shake_buf)\n",
    "                        if rms > SHAKE_RMS_PX:\n",
    "                            shake_start = shake_start or time.time()\n",
    "                        else:\n",
    "                            shake_start = None\n",
    "\n",
    "                        if shake_start and time.time() - shake_start >= SHAKE_SEC:\n",
    "                            drunk = True\n",
    "                else:\n",
    "                    shake_buf.clear()\n",
    "                    shake_start = None\n",
    "\n",
    "                # ================== Alerts & UI ==================\n",
    "                alerts = []\n",
    "                if drowsy:\n",
    "                    alerts.append(\"DROWSY\")\n",
    "                if drunk:\n",
    "                    alerts.append(\"DRUNK/UNWELL\")\n",
    "                if stressed:\n",
    "                    alerts.append(\"STRESS\")\n",
    "\n",
    "                for i, txt in enumerate(alerts):\n",
    "                    cv2.putText(frame, txt, (20, 120 + i * 50), \n",
    "                                cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "                if alerts and time.time() - last_beep > 0.8:\n",
    "                    play_beep()\n",
    "                    last_beep = time.time()\n",
    "                    print(*alerts, sep=\" | \")\n",
    "\n",
    "                # Add mic status visual indicator\n",
    "                mic_status = \"MIC ON\" if audio_thread.is_alive() else \"MIC ERROR\"\n",
    "                cv2.putText(frame, mic_status, (w-150, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                            (0, 255, 0) if audio_thread.is_alive() else (0, 0, 255), 2)\n",
    "\n",
    "                # ================== Key handling & display ==================\n",
    "                cv2.imshow(\"Driver Safety Suite\", frame)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord(' '):\n",
    "                    if blob:\n",
    "                        cx0 = blob[0]\n",
    "                        consecutive_lr = 0\n",
    "                        print(\"Steering centre calibrated at\", cx0)\n",
    "                    else:\n",
    "                        print(\"No sticker detected for calibration\")\n",
    "                elif key == ord('s'):  # Force stress test\n",
    "                    trigger_stress()\n",
    "                    print(\"Stress manually triggered\")\n",
    "                elif key == ord('b'):  # Test beep\n",
    "                    play_beep()\n",
    "                    print(\"Beep test\")\n",
    "                elif key == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78860fe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mDriver Safety Suite (final) with Arduino Communication\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m--------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mQ      – quit\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mthreading\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mqueue\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msubprocess\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaysound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m playsound\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m framework\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gpu\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/audio/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks Audio API.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classifier\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_embedder\u001b[39;00m\n\u001b[1;32m     21\u001b[0m AudioClassifier \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifier\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/audio/audio_classifier.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier_options_pb2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_task_running_mode \u001b[38;5;28;01mas\u001b[39;00m running_mode_module\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_audio_task_api\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_data \u001b[38;5;28;01mas\u001b[39;00m audio_data_module\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_result \u001b[38;5;28;01mas\u001b[39;00m classification_result_module\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/audio/core/base_audio_task_api.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_record\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_task_running_mode \u001b[38;5;28;01mas\u001b[39;00m running_mode_module\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptional_dependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_controls\n\u001b[1;32m     27\u001b[0m _TaskRunner \u001b[38;5;241m=\u001b[39m task_runner_module\u001b[38;5;241m.\u001b[39mTaskRunner\n\u001b[1;32m     28\u001b[0m _Packet \u001b[38;5;241m=\u001b[39m packet_module\u001b[38;5;241m.\u001b[39mPacket\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mediapipe/tasks/python/core/optional_dependencies.py:20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# TensorFlow isn't a dependency of mediapipe pip package. It's only\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# required in the API docgen pipeline so we'll ignore it if tensorflow is not\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# installed.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_controls\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m# Replace the real doc_controls.do_not_generate_docs with an no-op\u001b[39;00m\n\u001b[1;32m     23\u001b[0m   doc_controls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:45\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# pywrap_tensorflow must be imported first to avoid protobuf issues.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# (b/143110113)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# pylint: enable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:34\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Driver Safety Suite (final) with Arduino Communication\n",
    "--------------------------------\n",
    "* Steering direction (green sticker)\n",
    "* Drowsiness (eyes closed > 2 s)\n",
    "* Drunk / unwell  – head bowed > 1.5 s **or** shake RMS > 60 px sustained ≥ 3 s\n",
    "* Stress – shouting > 2 s **or** keywords \"FUCK\", \"MOVE ASIDE\" (offline ASR)\n",
    "\n",
    "Controls\n",
    "========\n",
    "SPACE  – calibrate steering centre\n",
    "S      - manually trigger stress (test)\n",
    "B      - test beep sound\n",
    "Q      – quit\n",
    "\"\"\"\n",
    "\n",
    "import cv2, mediapipe as mp, numpy as np, time, threading, queue, json, collections, subprocess, os, sys\n",
    "import sounddevice as sd\n",
    "from playsound import playsound\n",
    "import serial  # Added for Arduino communication\n",
    "\n",
    "try:\n",
    "    from vosk import Model, KaldiRecognizer\n",
    "    VOSK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: Vosk speech recognition not available\")\n",
    "    VOSK_AVAILABLE = False\n",
    "\n",
    "# ---------------------------- CONFIG ------------------------------------\n",
    "LOWER = np.array([40,  80,  80])      # HSV range for neon‑green sticker\n",
    "UPPER = np.array([85, 255, 255])\n",
    "STEER_DEAD_PX    = 60                 # half‑width of steering dead‑zone (px)\n",
    "STEER_FRAMES_REQ = 4                  # frames beyond dead‑zone before state flips\n",
    "\n",
    "EAR_TH        = 0.18                  # eye‑aspect‑ratio threshold\n",
    "DROWSY_SEC    = 2.0\n",
    "\n",
    "BOW_SEC       = 1.5\n",
    "SHAKE_RMS_PX  = 60\n",
    "SHAKE_SEC     = 3.0\n",
    "\n",
    "# Substantially lower thresholds for stress detection\n",
    "SHOUT_GAIN    = 10.0                  # Volume threshold multiplier\n",
    "SHOUT_SEC     = 1.0                   # Seconds required for shouting\n",
    "STRESS_DISPLAY_SEC = 5.0              # How long to display the stress warning\n",
    "\n",
    "KW_SET        = {\"FUCK\"}              # Individual keywords\n",
    "KW_PHRASES    = [\"MOVE ASIDE\"]        # Phrases to detect\n",
    "\n",
    "AUDIO_BLOCK   = 0.5                   # Half-second blocks for quicker response\n",
    "BEEP_PATH     = \"/Users/samridhgirdhar/Downloads/beep2.mp3\"  # Default beep sound\n",
    "MODEL_DIR     = \"vosk_en\"             # path to Vosk EN model directory\n",
    "\n",
    "# Arduino Serial Communication Configuration\n",
    "SERIAL_PORT = \"/dev/cu.usbmodem2101\"   # Arduino USB port - CHANGE THIS TO YOUR PORT\n",
    "BAUD_RATE = 9600\n",
    "SERIAL_TIMEOUT = 0.1                  # Short timeout for non-blocking\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------- HELPERS -----------------------------------\n",
    "mp_face = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "LIDS_L  = [33,160,158,133,153,144]\n",
    "LIDS_R  = [362,385,387,263,373,380]\n",
    "\n",
    "def find_blob(mask):\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    M = cv2.moments(c)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return None\n",
    "    return int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "def ear(pts, idx):\n",
    "    \"\"\"Compute eye‑aspect‑ratio for given 6‑point lid indices.\"\"\"\n",
    "    p2p6 = np.linalg.norm(pts[idx[1]] - pts[idx[5]])\n",
    "    p3p5 = np.linalg.norm(pts[idx[2]] - pts[idx[4]])\n",
    "    p1p4 = np.linalg.norm(pts[idx[0]] - pts[idx[3]])\n",
    "    return (p2p6 + p3p5) / (2.0 * p1p4)\n",
    "\n",
    "def play_beep():\n",
    "    \"\"\"Simple beep function that works across platforms.\"\"\"\n",
    "    print(\"\\a\", end=\"\", flush=True)  # System bell as default\n",
    "    \n",
    "    try:\n",
    "        # Use platform-specific commands for more reliable sound\n",
    "        if sys.platform == 'win32':\n",
    "            import winsound\n",
    "            winsound.Beep(1000, 500)\n",
    "        elif sys.platform == 'darwin':  # macOS\n",
    "            subprocess.run(['afplay', '/System/Library/Sounds/Tink.aiff'], \n",
    "                          check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        elif sys.platform == 'linux':\n",
    "            subprocess.run(['paplay', '/usr/share/sounds/freedesktop/stereo/complete.oga'],\n",
    "                          check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    except Exception:\n",
    "        pass  # Fallback to system bell already done\n",
    "\n",
    "# Function to send data to Arduino\n",
    "def send_to_arduino(ser, message):\n",
    "    \"\"\"Send a message to Arduino with newline termination.\"\"\"\n",
    "    if ser and ser.is_open:\n",
    "        try:\n",
    "            ser.write((message + \"\\n\").encode())\n",
    "            print(f\"[ARDUINO] Sent: {message}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ARDUINO] Error sending data: {e}\")\n",
    "\n",
    "# ----------------------- AUDIO / STRESS DETECTION --------------------------\n",
    "\n",
    "def setup_vosk(sample_rate=16000):\n",
    "    \"\"\"Set up Vosk speech recognition if available.\"\"\"\n",
    "    if not VOSK_AVAILABLE:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        model = Model(MODEL_DIR) \n",
    "        return KaldiRecognizer(model, sample_rate)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR setting up Vosk: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_audio(stress_callback):\n",
    "    \"\"\"Process audio in a separate thread and detect stress via shouting or keywords.\"\"\"\n",
    "    fs = 16000\n",
    "    \n",
    "    # Try to set up speech recognition\n",
    "    recognizer = setup_vosk(fs)\n",
    "    speech_recognition = recognizer is not None\n",
    "    \n",
    "    print(f\"Audio processing thread started. Speech recognition: {speech_recognition}\")\n",
    "    \n",
    "    # Energy tracking variables\n",
    "    audio_energies = collections.deque(maxlen=20)  # ~10 seconds history\n",
    "    high_energy_start = None\n",
    "    baseline_multiplier = 1.0  # Start with normal sensitivity\n",
    "    \n",
    "    # Initial baseline calculation period\n",
    "    print(\"Calculating audio baseline... please stay quiet\")\n",
    "    for _ in range(5):  # ~2.5 seconds to establish baseline\n",
    "        audio = sd.rec(int(AUDIO_BLOCK * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "        sd.wait()\n",
    "        block = audio.flatten()\n",
    "        energy = np.sqrt(np.mean(block ** 2))\n",
    "        audio_energies.append(energy)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    baseline_energy = np.mean(audio_energies) * 1.2  # Add 20% margin\n",
    "    print(f\"Audio baseline established: {baseline_energy:.6f}\")\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Record audio\n",
    "            audio = sd.rec(int(AUDIO_BLOCK * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "            sd.wait()\n",
    "            block = audio.flatten()\n",
    "            \n",
    "            # Calculate energy and update rolling history\n",
    "            energy = np.sqrt(np.mean(block ** 2))\n",
    "            audio_energies.append(energy)\n",
    "            \n",
    "            # Gradually update baseline to adapt to environment\n",
    "            if len(audio_energies) >= 10:  # Wait for enough history\n",
    "                # Use the 20th percentile as the baseline for better stability\n",
    "                sorted_energies = sorted(audio_energies)\n",
    "                baseline_energy = sorted_energies[int(len(sorted_energies) * 0.2)]\n",
    "            \n",
    "            # Print energy levels occasionally for debugging\n",
    "            if np.random.random() < 0.05:  # ~5% of blocks\n",
    "                energy_ratio = energy / baseline_energy\n",
    "                print(f\"Audio: energy={energy:.6f}, baseline={baseline_energy:.6f}, ratio={energy_ratio:.2f}\")\n",
    "            \n",
    "            # Shouting detection\n",
    "            if energy > baseline_energy * SHOUT_GAIN * baseline_multiplier:\n",
    "                if high_energy_start is None:\n",
    "                    high_energy_start = time.time()\n",
    "                    print(f\"High volume detected! Ratio: {energy/baseline_energy:.2f}\")\n",
    "            else:\n",
    "                high_energy_start = None\n",
    "            \n",
    "            # If high energy sustains long enough, trigger stress\n",
    "            if high_energy_start and (time.time() - high_energy_start) >= SHOUT_SEC:\n",
    "                print(\"STRESS DETECTED: SHOUTING\")\n",
    "                stress_callback()\n",
    "                high_energy_start = None\n",
    "                # Temporarily increase sensitivity for next few seconds\n",
    "                baseline_multiplier = 0.8\n",
    "                time.sleep(1.0)  # Pause briefly to avoid rapid retriggers\n",
    "                continue\n",
    "            \n",
    "            # Restore normal sensitivity over time\n",
    "            baseline_multiplier = min(1.0, baseline_multiplier + 0.01)\n",
    "            \n",
    "            # Speech recognition for keywords\n",
    "            if speech_recognition:\n",
    "                # Convert float32 → int16 PCM for Vosk\n",
    "                block_int16 = (block * 32767).astype(np.int16).tobytes()\n",
    "                \n",
    "                if recognizer.AcceptWaveform(block_int16):\n",
    "                    result = json.loads(recognizer.Result())\n",
    "                    transcript = result.get(\"text\", \"\").upper()\n",
    "                    \n",
    "                    if transcript:\n",
    "                        print(f\"Speech: {transcript}\")\n",
    "                        \n",
    "                        # Check for keywords\n",
    "                        found_keywords = [w for w in transcript.split() if w in KW_SET]\n",
    "                        \n",
    "                        # Check for phrases\n",
    "                        found_phrases = [p for p in KW_PHRASES if p in transcript]\n",
    "                        \n",
    "                        if found_keywords:\n",
    "                            print(f\"STRESS DETECTED: Keywords {found_keywords}\")\n",
    "                            stress_callback()\n",
    "                        \n",
    "                        if found_phrases:\n",
    "                            print(f\"STRESS DETECTED: Phrase {found_phrases}\")\n",
    "                            stress_callback()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Audio error: {e}\")\n",
    "            time.sleep(1)  # Avoid error spam\n",
    "\n",
    "# ----------------------------- MAIN -------------------------------------\n",
    "\n",
    "def main(cam_index: int = 1):\n",
    "    try:\n",
    "        # Initialize camera\n",
    "        cap = cv2.VideoCapture(cam_index)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Camera not found - trying default camera\")\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            if not cap.isOpened():\n",
    "                raise RuntimeError(\"No cameras found - please connect a webcam or enable camera access\")\n",
    "\n",
    "        # Initialize serial connection to Arduino\n",
    "        ser = None\n",
    "        try:\n",
    "            ser = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=SERIAL_TIMEOUT)\n",
    "            print(f\"[ARDUINO] Connected to {SERIAL_PORT} at {BAUD_RATE} baud\")\n",
    "            # Give Arduino time to reset after connection\n",
    "            time.sleep(2)\n",
    "            # Send initial message to test connection\n",
    "            send_to_arduino(ser, \"SYSTEM:READY\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ARDUINO] Connection failed: {e}\")\n",
    "            print(\"[ARDUINO] Continuing without Arduino communication\")\n",
    "\n",
    "        # ------- steering state -------\n",
    "        cx0 = None\n",
    "        steer_state = \"STRAIGHT\"\n",
    "        last_steer_state = None\n",
    "        consecutive_lr = 0\n",
    "\n",
    "        # ------- timers & buffers -------\n",
    "        eye_closed_start = None\n",
    "        head_bow_start   = None\n",
    "        shake_start      = None\n",
    "        shake_buf        = collections.deque(maxlen=30)  # ≈1 s at 30 fps\n",
    "        last_beep = 0\n",
    "        \n",
    "        # ------- state tracking -------\n",
    "        last_drowsy = False\n",
    "        last_drunk = False\n",
    "        \n",
    "        # ------- stress state -------\n",
    "        stressed = False\n",
    "        last_stressed = False\n",
    "        stress_end_time = 0\n",
    "        \n",
    "        def trigger_stress():\n",
    "            nonlocal stressed, stress_end_time\n",
    "            stressed = True\n",
    "            stress_end_time = time.time() + STRESS_DISPLAY_SEC\n",
    "            play_beep()\n",
    "        \n",
    "        # Start audio processing in background thread\n",
    "        audio_thread = threading.Thread(\n",
    "            target=process_audio,\n",
    "            args=(trigger_stress,),\n",
    "            daemon=True\n",
    "        )\n",
    "        audio_thread.start()\n",
    "\n",
    "        # Wait a moment for audio thread to initialize\n",
    "        time.sleep(2)\n",
    "        print(\"Driver Safety Suite started. Press SPACE to calibrate steering, Q to quit.\")\n",
    "\n",
    "        with mp_face.FaceMesh(max_num_faces=1, refine_landmarks=True,\n",
    "                            min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh, \\\n",
    "            mp_pose.Pose(static_image_mode=False) as pose:\n",
    "            \n",
    "            while True:\n",
    "                # Get frame from camera\n",
    "                ok, frame = cap.read()\n",
    "                if not ok:\n",
    "                    print(\"Camera read failed\")\n",
    "                    break\n",
    "                \n",
    "                h, w = frame.shape[:2]\n",
    "                \n",
    "                # Reset stress flag if timeout elapsed\n",
    "                if stressed and time.time() > stress_end_time:\n",
    "                    stressed = False\n",
    "\n",
    "                # ================== Steering detection ==================\n",
    "                hsv  = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                mask = cv2.inRange(hsv, LOWER, UPPER)\n",
    "                mask = cv2.erode(mask, None, 2)\n",
    "                mask = cv2.dilate(mask, None, 2)\n",
    "                blob = find_blob(mask)\n",
    "\n",
    "                if blob and cx0 is not None:\n",
    "                    dx = blob[0] - cx0\n",
    "                    if abs(dx) > STEER_DEAD_PX:\n",
    "                        consecutive_lr += 1\n",
    "                        if consecutive_lr >= STEER_FRAMES_REQ:\n",
    "                            steer_state = \"LEFT\" if dx < 0 else \"RIGHT\"\n",
    "                            consecutive_lr = STEER_FRAMES_REQ\n",
    "                    else:\n",
    "                        consecutive_lr = 0\n",
    "                        steer_state = \"STRAIGHT\"\n",
    "                elif not blob:\n",
    "                    steer_state = \"STKR MISS\"\n",
    "                else:\n",
    "                    steer_state = \"UN CAL\"\n",
    "\n",
    "                cv2.putText(frame, steer_state, (20, 60), cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "                # Send steering state to Arduino if changed\n",
    "                if steer_state != last_steer_state and steer_state in (\"LEFT\", \"RIGHT\", \"STRAIGHT\"):\n",
    "                    send_to_arduino(ser, f\"STEER:{steer_state}\")\n",
    "                last_steer_state = steer_state\n",
    "\n",
    "                # ================== Face & pose landmarks ==================\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                face_res = face_mesh.process(rgb)\n",
    "                pose_res = pose.process(rgb)\n",
    "\n",
    "                drowsy = False\n",
    "                drunk  = False\n",
    "\n",
    "                # ---------- drowsiness via eyes ----------\n",
    "                if face_res.multi_face_landmarks:\n",
    "                    pts = np.array([(p.x * w, p.y * h) for p in face_res.multi_face_landmarks[0].landmark])\n",
    "                    ear_now = (ear(pts, LIDS_L) + ear(pts, LIDS_R)) / 2\n",
    "\n",
    "                    if ear_now < EAR_TH:\n",
    "                        eye_closed_start = eye_closed_start or time.time()\n",
    "                    else:\n",
    "                        eye_closed_start = None\n",
    "\n",
    "                    if eye_closed_start and time.time() - eye_closed_start >= DROWSY_SEC:\n",
    "                        drowsy = True\n",
    "\n",
    "                    # ---------- head bow ----------\n",
    "                    eye_y  = pts[1][1]\n",
    "                    chin_y = pts[152][1]\n",
    "                    bowed = (eye_y - chin_y) > 40\n",
    "                    if bowed:\n",
    "                        head_bow_start = head_bow_start or time.time()\n",
    "                    else:\n",
    "                        head_bow_start = None\n",
    "                    if head_bow_start and time.time() - head_bow_start >= BOW_SEC:\n",
    "                        drunk = True\n",
    "\n",
    "                # ---------- shake detection ----------\n",
    "                if pose_res.pose_landmarks:\n",
    "                    nose_x = pose_res.pose_landmarks.landmark[0].x * w\n",
    "                    shake_buf.append(nose_x)\n",
    "                    if len(shake_buf) == shake_buf.maxlen:\n",
    "                        rms = np.std(shake_buf)\n",
    "                        if rms > SHAKE_RMS_PX:\n",
    "                            shake_start = shake_start or time.time()\n",
    "                        else:\n",
    "                            shake_start = None\n",
    "\n",
    "                        if shake_start and time.time() - shake_start >= SHAKE_SEC:\n",
    "                            drunk = True\n",
    "                else:\n",
    "                    shake_buf.clear()\n",
    "                    shake_start = None\n",
    "\n",
    "                # ================== Send state changes to Arduino ==================\n",
    "                # Send drowsy state change\n",
    "                if drowsy != last_drowsy:\n",
    "                    if drowsy:\n",
    "                        send_to_arduino(ser, \"ALERT:DROWSY\")\n",
    "                    else:\n",
    "                        send_to_arduino(ser, \"CLEAR:DROWSY\")\n",
    "                last_drowsy = drowsy\n",
    "                \n",
    "                # Send drunk/unwell state change\n",
    "                if drunk != last_drunk:\n",
    "                    if drunk:\n",
    "                        send_to_arduino(ser, \"ALERT:DRUNK\")\n",
    "                    else:\n",
    "                        send_to_arduino(ser, \"CLEAR:DRUNK\")\n",
    "                last_drunk = drunk\n",
    "                \n",
    "                # Send stress state change\n",
    "                if stressed != last_stressed:\n",
    "                    if stressed:\n",
    "                        send_to_arduino(ser, \"ALERT:STRESS\")\n",
    "                    else:\n",
    "                        send_to_arduino(ser, \"CLEAR:STRESS\")\n",
    "                last_stressed = stressed\n",
    "\n",
    "                # ================== Alerts & UI ==================\n",
    "                alerts = []\n",
    "                if drowsy:\n",
    "                    alerts.append(\"DROWSY\")\n",
    "                if drunk:\n",
    "                    alerts.append(\"DRUNK/UNWELL\")\n",
    "                if stressed:\n",
    "                    alerts.append(\"STRESS\")\n",
    "\n",
    "                for i, txt in enumerate(alerts):\n",
    "                    cv2.putText(frame, txt, (20, 120 + i * 50), \n",
    "                                cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "                if alerts and time.time() - last_beep > 0.8:\n",
    "                    play_beep()\n",
    "                    last_beep = time.time()\n",
    "                    print(*alerts, sep=\" | \")\n",
    "\n",
    "                # Add mic status visual indicator\n",
    "                mic_status = \"MIC ON\" if audio_thread.is_alive() else \"MIC ERROR\"\n",
    "                cv2.putText(frame, mic_status, (w-150, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                            (0, 255, 0) if audio_thread.is_alive() else (0, 0, 255), 2)\n",
    "                \n",
    "                # Add Arduino status indicator\n",
    "                arduino_status = \"ARDUINO ON\" if (ser and ser.is_open) else \"ARDUINO OFF\"\n",
    "                cv2.putText(frame, arduino_status, (w-150, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                            (0, 255, 0) if (ser and ser.is_open) else (0, 0, 255), 2)\n",
    "\n",
    "                # ================== Key handling & display ==================\n",
    "                cv2.imshow(\"Driver Safety Suite\", frame)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord(' '):\n",
    "                    if blob:\n",
    "                        cx0 = blob[0]\n",
    "                        consecutive_lr = 0\n",
    "                        print(\"Steering centre calibrated at\", cx0)\n",
    "                        send_to_arduino(ser, \"SYSTEM:CALIBRATED\")\n",
    "                    else:\n",
    "                        print(\"No sticker detected for calibration\")\n",
    "                elif key == ord('s'):  # Force stress test\n",
    "                    trigger_stress()\n",
    "                    print(\"Stress manually triggered\")\n",
    "                elif key == ord('b'):  # Test beep\n",
    "                    play_beep()\n",
    "                    print(\"Beep test\")\n",
    "                elif key == ord('q'):\n",
    "                    # Send shutdown message to Arduino\n",
    "                    send_to_arduino(ser, \"SYSTEM:SHUTDOWN\")\n",
    "                    break\n",
    "\n",
    "        # Clean up\n",
    "        if ser and ser.is_open:\n",
    "            ser.close()\n",
    "            print(\"[ARDUINO] Connection closed\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 20:59:55.455 Python[47890:1290722] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARDUINO] Connected to /dev/cu.usbmodem2101 at 9600 baud\n",
      "[ARDUINO] Sent: SYSTEM:READY\n",
      "[ASSISTANT] Error sending to assistant: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /alert (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x321b8e1d0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "[ASSISTANT] Connection established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from vosk_en/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from vosk_en/graph/HCLr.fst vosk_en/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo vosk_en/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio processing thread started. Speech recognition: True\n",
      "Calculating audio baseline... please stay quiet\n",
      "Driver Safety Suite started. Press SPACE to calibrate steering, Q to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745335800.914090 1290722 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1745335800.925997 1290722 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "W0000 00:00:1745335800.930135 1291556 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745335800.947519 1291556 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745335800.963258 1291555 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1745335801.024733 1291564 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745335801.041719 1291564 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-04-22 21:00:01.502 Python[47890:1290722] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-22 21:00:01.502 Python[47890:1290722] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio baseline established: 0.045812\n",
      "Audio: energy=0.040678, baseline=0.045812, ratio=0.89\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Driver Safety Suite (complete) with Arduino Communication and AI Assistant Integration\n",
    "------------------------------------------------------------------------------------\n",
    "* Steering direction (green sticker)\n",
    "* Drowsiness (eyes closed > 2 s)\n",
    "* Drunk / unwell  – head bowed > 1.5 s **or** shake RMS > 60 px sustained ≥ 3 s\n",
    "* Stress – shouting > 2 s **or** keywords \"FUCK\", \"MOVE ASIDE\" (offline ASR)\n",
    "\n",
    "Controls\n",
    "========\n",
    "SPACE  – calibrate steering centre\n",
    "S      - manually trigger stress (test)\n",
    "B      - test beep sound\n",
    "Q      – quit\n",
    "\"\"\"\n",
    "\n",
    "import cv2, mediapipe as mp, numpy as np, time, threading, queue, json, collections, subprocess, os, sys\n",
    "import sounddevice as sd\n",
    "from playsound import playsound\n",
    "import serial  # For Arduino communication\n",
    "import requests  # For AI assistant communication\n",
    "\n",
    "try:\n",
    "    from vosk import Model, KaldiRecognizer\n",
    "    VOSK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: Vosk speech recognition not available\")\n",
    "    VOSK_AVAILABLE = False\n",
    "\n",
    "# ---------------------------- CONFIG ------------------------------------\n",
    "LOWER = np.array([40,  80,  80])      # HSV range for neon‑green sticker\n",
    "UPPER = np.array([85, 255, 255])\n",
    "STEER_DEAD_PX    = 60                 # half‑width of steering dead‑zone (px)\n",
    "STEER_FRAMES_REQ = 4                  # frames beyond dead‑zone before state flips\n",
    "\n",
    "EAR_TH        = 0.18                  # eye‑aspect‑ratio threshold\n",
    "DROWSY_SEC    = 2.0\n",
    "\n",
    "BOW_SEC       = 1.5\n",
    "SHAKE_RMS_PX  = 60\n",
    "SHAKE_SEC     = 3.0\n",
    "\n",
    "# Substantially lower thresholds for stress detection\n",
    "SHOUT_GAIN    = 15.0                  # Volume threshold multiplier\n",
    "SHOUT_SEC     = 1.0                   # Seconds required for shouting\n",
    "STRESS_DISPLAY_SEC = 5.0              # How long to display the stress warning\n",
    "\n",
    "KW_SET        = {\"FUCK\"}              # Individual keywords\n",
    "KW_PHRASES    = [\"MOVE ASIDE\"]        # Phrases to detect\n",
    "\n",
    "AUDIO_BLOCK   = 0.5                   # Half-second blocks for quicker response\n",
    "BEEP_PATH     = \"/Users/samridhgirdhar/Downloads/beep2.mp3\"  # Default beep sound\n",
    "MODEL_DIR     = \"vosk_en\"             # path to Vosk EN model directory\n",
    "\n",
    "# Arduino Serial Communication Configuration\n",
    "SERIAL_PORT = \"/dev/cu.usbmodem2101\"   # Arduino USB port - CHANGE THIS TO YOUR PORT\n",
    "BAUD_RATE = 9600\n",
    "SERIAL_TIMEOUT = 0.1                  # Short timeout for non-blocking\n",
    "\n",
    "# AI Assistant Communication Configuration\n",
    "ASSISTANT_URL = \"http://localhost:8080/alert\"  # AI Assistant API endpoint\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------- HELPERS -----------------------------------\n",
    "mp_face = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "LIDS_L  = [33,160,158,133,153,144]\n",
    "LIDS_R  = [362,385,387,263,373,380]\n",
    "\n",
    "def find_blob(mask):\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    M = cv2.moments(c)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return None\n",
    "    return int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "def ear(pts, idx):\n",
    "    \"\"\"Compute eye‑aspect‑ratio for given 6‑point lid indices.\"\"\"\n",
    "    p2p6 = np.linalg.norm(pts[idx[1]] - pts[idx[5]])\n",
    "    p3p5 = np.linalg.norm(pts[idx[2]] - pts[idx[4]])\n",
    "    p1p4 = np.linalg.norm(pts[idx[0]] - pts[idx[3]])\n",
    "    return (p2p6 + p3p5) / (2.0 * p1p4)\n",
    "\n",
    "def play_beep():\n",
    "    \"\"\"Simple beep function that works across platforms.\"\"\"\n",
    "    print(\"\\a\", end=\"\", flush=True)  # System bell as default\n",
    "    \n",
    "    try:\n",
    "        # Use platform-specific commands for more reliable sound\n",
    "        if sys.platform == 'win32':  # Windows\n",
    "            import winsound\n",
    "            winsound.Beep(1000, 500)\n",
    "        elif sys.platform == 'darwin':  # macOS\n",
    "            subprocess.run(['afplay', '/System/Library/Sounds/Tink.aiff'], \n",
    "                          check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        elif sys.platform == 'linux':\n",
    "            subprocess.run(['paplay', '/usr/share/sounds/freedesktop/stereo/complete.oga'],\n",
    "                          check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    except Exception:\n",
    "        pass  # Fallback to system bell already done\n",
    "\n",
    "# Function to send data to Arduino\n",
    "def send_to_arduino(ser, message):\n",
    "    \"\"\"Send a message to Arduino with newline termination.\"\"\"\n",
    "    if ser and ser.is_open:\n",
    "        try:\n",
    "            ser.write((message + \"\\n\").encode())\n",
    "            print(f\"[ARDUINO] Sent: {message}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ARDUINO] Error sending data: {e}\")\n",
    "\n",
    "# Function to send data to AI Assistant\n",
    "def send_to_assistant(alert_type, state=True, additional_data=None):\n",
    "    \"\"\"Send an alert to the AI assistant.\"\"\"\n",
    "    try:\n",
    "        data = {\n",
    "            \"type\": alert_type,\n",
    "            \"state\": state\n",
    "        }\n",
    "        \n",
    "        if additional_data:\n",
    "            data.update(additional_data)\n",
    "            \n",
    "        response = requests.post(ASSISTANT_URL, json=data, timeout=0.5)  # Short timeout to avoid blocking\n",
    "        if response.status_code == 200:\n",
    "            print(f\"[ASSISTANT] Sent {alert_type} alert\")\n",
    "        else:\n",
    "            print(f\"[ASSISTANT] Failed to send alert: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ASSISTANT] Error sending to assistant: {e}\")\n",
    "\n",
    "# ----------------------- AUDIO / STRESS DETECTION --------------------------\n",
    "\n",
    "def setup_vosk(sample_rate=16000):\n",
    "    \"\"\"Set up Vosk speech recognition if available.\"\"\"\n",
    "    if not VOSK_AVAILABLE:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        model = Model(MODEL_DIR) \n",
    "        return KaldiRecognizer(model, sample_rate)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR setting up Vosk: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_audio(stress_callback):\n",
    "    \"\"\"Process audio in a separate thread and detect stress via shouting or keywords.\"\"\"\n",
    "    fs = 16000\n",
    "    \n",
    "    # Try to set up speech recognition\n",
    "    recognizer = setup_vosk(fs)\n",
    "    speech_recognition = recognizer is not None\n",
    "    \n",
    "    print(f\"Audio processing thread started. Speech recognition: {speech_recognition}\")\n",
    "    \n",
    "    # Energy tracking variables\n",
    "    audio_energies = collections.deque(maxlen=20)  # ~10 seconds history\n",
    "    high_energy_start = None\n",
    "    baseline_multiplier = 1.0  # Start with normal sensitivity\n",
    "    \n",
    "    # Initial baseline calculation period\n",
    "    print(\"Calculating audio baseline... please stay quiet\")\n",
    "    for _ in range(5):  # ~2.5 seconds to establish baseline\n",
    "        audio = sd.rec(int(AUDIO_BLOCK * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "        sd.wait()\n",
    "        block = audio.flatten()\n",
    "        energy = np.sqrt(np.mean(block ** 2))\n",
    "        audio_energies.append(energy)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    baseline_energy = np.mean(audio_energies) * 1.2  # Add 20% margin\n",
    "    print(f\"Audio baseline established: {baseline_energy:.6f}\")\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Record audio\n",
    "            audio = sd.rec(int(AUDIO_BLOCK * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "            sd.wait()\n",
    "            block = audio.flatten()\n",
    "            \n",
    "            # Calculate energy and update rolling history\n",
    "            energy = np.sqrt(np.mean(block ** 2))\n",
    "            audio_energies.append(energy)\n",
    "            \n",
    "            # Gradually update baseline to adapt to environment\n",
    "            if len(audio_energies) >= 10:  # Wait for enough history\n",
    "                # Use the 20th percentile as the baseline for better stability\n",
    "                sorted_energies = sorted(audio_energies)\n",
    "                baseline_energy = sorted_energies[int(len(sorted_energies) * 0.2)]\n",
    "            \n",
    "            # Print energy levels occasionally for debugging\n",
    "            if np.random.random() < 0.05:  # ~5% of blocks\n",
    "                energy_ratio = energy / baseline_energy\n",
    "                print(f\"Audio: energy={energy:.6f}, baseline={baseline_energy:.6f}, ratio={energy_ratio:.2f}\")\n",
    "            \n",
    "            # Shouting detection\n",
    "            if energy > baseline_energy * SHOUT_GAIN * baseline_multiplier:\n",
    "                if high_energy_start is None:\n",
    "                    high_energy_start = time.time()\n",
    "                    print(f\"High volume detected! Ratio: {energy/baseline_energy:.2f}\")\n",
    "            else:\n",
    "                high_energy_start = None\n",
    "            \n",
    "            # If high energy sustains long enough, trigger stress\n",
    "            if high_energy_start and (time.time() - high_energy_start) >= SHOUT_SEC:\n",
    "                print(\"STRESS DETECTED: SHOUTING\")\n",
    "                stress_callback()\n",
    "                high_energy_start = None\n",
    "                # Temporarily increase sensitivity for next few seconds\n",
    "                baseline_multiplier = 0.8\n",
    "                time.sleep(1.0)  # Pause briefly to avoid rapid retriggers\n",
    "                continue\n",
    "            \n",
    "            # Restore normal sensitivity over time\n",
    "            baseline_multiplier = min(1.0, baseline_multiplier + 0.01)\n",
    "            \n",
    "            # Speech recognition for keywords\n",
    "            if speech_recognition:\n",
    "                # Convert float32 → int16 PCM for Vosk\n",
    "                block_int16 = (block * 32767).astype(np.int16).tobytes()\n",
    "                \n",
    "                if recognizer.AcceptWaveform(block_int16):\n",
    "                    result = json.loads(recognizer.Result())\n",
    "                    transcript = result.get(\"text\", \"\").upper()\n",
    "                    \n",
    "                    if transcript:\n",
    "                        print(f\"Speech: {transcript}\")\n",
    "                        \n",
    "                        # Check for keywords\n",
    "                        found_keywords = [w for w in transcript.split() if w in KW_SET]\n",
    "                        \n",
    "                        # Check for phrases\n",
    "                        found_phrases = [p for p in KW_PHRASES if p in transcript]\n",
    "                        \n",
    "                        if found_keywords:\n",
    "                            print(f\"STRESS DETECTED: Keywords {found_keywords}\")\n",
    "                            stress_callback()\n",
    "                        \n",
    "                        if found_phrases:\n",
    "                            print(f\"STRESS DETECTED: Phrase {found_phrases}\")\n",
    "                            stress_callback()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Audio error: {e}\")\n",
    "            time.sleep(1)  # Avoid error spam\n",
    "\n",
    "# Function to process sensor data from MIT App Inventor\n",
    "def process_sensor_data(data):\n",
    "    \"\"\"Process sensor data received from the mobile app.\"\"\"\n",
    "    try:\n",
    "        # Extract accelerometer data\n",
    "        x_accel = data.get(\"x_accel\", 0)\n",
    "        y_accel = data.get(\"y_accel\", 0)\n",
    "        z_accel = data.get(\"z_accel\", 0)\n",
    "        \n",
    "        # Calculate total acceleration magnitude\n",
    "        total_accel = np.sqrt(x_accel**2 + y_accel**2 + z_accel**2)\n",
    "        \n",
    "        # Check for crash (acceleration spike greater than 2G)\n",
    "        if total_accel > 2:\n",
    "            print(f\"CRASH DETECTED: Acceleration = {total_accel:.2f}G\")\n",
    "            send_to_assistant(\"CRASH\", True)\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sensor data: {e}\")\n",
    "        return False\n",
    "\n",
    "# ----------------------------- MAIN -------------------------------------\n",
    "\n",
    "def main(cam_index: int = 1):\n",
    "    try:\n",
    "        # Initialize camera\n",
    "        cap = cv2.VideoCapture(cam_index)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Camera not found - trying default camera\")\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            if not cap.isOpened():\n",
    "                raise RuntimeError(\"No cameras found - please connect a webcam or enable camera access\")\n",
    "\n",
    "        # Initialize serial connection to Arduino\n",
    "        ser = None\n",
    "        try:\n",
    "            ser = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=SERIAL_TIMEOUT)\n",
    "            print(f\"[ARDUINO] Connected to {SERIAL_PORT} at {BAUD_RATE} baud\")\n",
    "            # Give Arduino time to reset after connection\n",
    "            time.sleep(2)\n",
    "            # Send initial message to test connection\n",
    "            send_to_arduino(ser, \"SYSTEM:READY\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ARDUINO] Connection failed: {e}\")\n",
    "            print(\"[ARDUINO] Continuing without Arduino communication\")\n",
    "\n",
    "        # Send system ready to assistant\n",
    "        try:\n",
    "            send_to_assistant(\"SYSTEM\", True, {\"message\": \"READY\"})\n",
    "            print(\"[ASSISTANT] Connection established\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ASSISTANT] Connection failed: {e}\")\n",
    "            print(\"[ASSISTANT] Continuing without AI assistant\")\n",
    "\n",
    "        # ------- steering state -------\n",
    "        cx0 = None\n",
    "        steer_state = \"STRAIGHT\"\n",
    "        last_steer_state = None\n",
    "        consecutive_lr = 0\n",
    "\n",
    "        # ------- timers & buffers -------\n",
    "        eye_closed_start = None\n",
    "        head_bow_start   = None\n",
    "        shake_start      = None\n",
    "        shake_buf        = collections.deque(maxlen=30)  # ≈1 s at 30 fps\n",
    "        last_beep = 0\n",
    "        \n",
    "        # ------- state tracking -------\n",
    "        last_drowsy = False\n",
    "        last_drunk = False\n",
    "        \n",
    "        # ------- stress state -------\n",
    "        stressed = False\n",
    "        last_stressed = False\n",
    "        stress_end_time = 0\n",
    "        \n",
    "        def trigger_stress():\n",
    "            nonlocal stressed, stress_end_time\n",
    "            stressed = True\n",
    "            stress_end_time = time.time() + STRESS_DISPLAY_SEC\n",
    "            play_beep()\n",
    "        \n",
    "        # Start audio processing in background thread\n",
    "        audio_thread = threading.Thread(\n",
    "            target=process_audio,\n",
    "            args=(trigger_stress,),\n",
    "            daemon=True\n",
    "        )\n",
    "        audio_thread.start()\n",
    "\n",
    "        # Wait a moment for audio thread to initialize\n",
    "        time.sleep(2)\n",
    "        print(\"Driver Safety Suite started. Press SPACE to calibrate steering, Q to quit.\")\n",
    "\n",
    "        with mp_face.FaceMesh(max_num_faces=1, refine_landmarks=True,\n",
    "                            min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh, \\\n",
    "            mp_pose.Pose(static_image_mode=False) as pose:\n",
    "            \n",
    "            while True:\n",
    "                # Get frame from camera\n",
    "                ok, frame = cap.read()\n",
    "                if not ok:\n",
    "                    print(\"Camera read failed\")\n",
    "                    break\n",
    "                \n",
    "                h, w = frame.shape[:2]\n",
    "                \n",
    "                # Reset stress flag if timeout elapsed\n",
    "                if stressed and time.time() > stress_end_time:\n",
    "                    stressed = False\n",
    "\n",
    "                # ================== Steering detection ==================\n",
    "                hsv  = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                mask = cv2.inRange(hsv, LOWER, UPPER)\n",
    "                mask = cv2.erode(mask, None, 2)\n",
    "                mask = cv2.dilate(mask, None, 2)\n",
    "                blob = find_blob(mask)\n",
    "\n",
    "                if blob and cx0 is not None:\n",
    "                    dx = blob[0] - cx0\n",
    "                    if abs(dx) > STEER_DEAD_PX:\n",
    "                        consecutive_lr += 1\n",
    "                        if consecutive_lr >= STEER_FRAMES_REQ:\n",
    "                            steer_state = \"LEFT\" if dx < 0 else \"RIGHT\"\n",
    "                            consecutive_lr = STEER_FRAMES_REQ\n",
    "                    else:\n",
    "                        consecutive_lr = 0\n",
    "                        steer_state = \"STRAIGHT\"\n",
    "                elif not blob:\n",
    "                    steer_state = \"STKR MISS\"\n",
    "                else:\n",
    "                    steer_state = \"UN CAL\"\n",
    "\n",
    "                cv2.putText(frame, steer_state, (20, 60), cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "                # Send steering state to Arduino and AI assistant if changed\n",
    "                if steer_state != last_steer_state and steer_state in (\"LEFT\", \"RIGHT\", \"STRAIGHT\"):\n",
    "                    send_to_arduino(ser, f\"STEER:{steer_state}\")\n",
    "                    send_to_assistant(\"STEER\", True, {\"direction\": steer_state})\n",
    "                last_steer_state = steer_state\n",
    "\n",
    "                # ================== Face & pose landmarks ==================\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                face_res = face_mesh.process(rgb)\n",
    "                pose_res = pose.process(rgb)\n",
    "\n",
    "                drowsy = False\n",
    "                drunk  = False\n",
    "\n",
    "                # ---------- drowsiness via eyes ----------\n",
    "                if face_res.multi_face_landmarks:\n",
    "                    pts = np.array([(p.x * w, p.y * h) for p in face_res.multi_face_landmarks[0].landmark])\n",
    "                    ear_now = (ear(pts, LIDS_L) + ear(pts, LIDS_R)) / 2\n",
    "\n",
    "                    if ear_now < EAR_TH:\n",
    "                        eye_closed_start = eye_closed_start or time.time()\n",
    "                    else:\n",
    "                        eye_closed_start = None\n",
    "\n",
    "                    if eye_closed_start and time.time() - eye_closed_start >= DROWSY_SEC:\n",
    "                        drowsy = True\n",
    "\n",
    "                    # ---------- head bow ----------\n",
    "                    eye_y  = pts[1][1]\n",
    "                    chin_y = pts[152][1]\n",
    "                    bowed = (eye_y - chin_y) > 40\n",
    "                    if bowed:\n",
    "                        head_bow_start = head_bow_start or time.time()\n",
    "                    else:\n",
    "                        head_bow_start = None\n",
    "                    if head_bow_start and time.time() - head_bow_start >= BOW_SEC:\n",
    "                        drunk = True\n",
    "\n",
    "                # ---------- shake detection ----------\n",
    "                if pose_res.pose_landmarks:\n",
    "                    nose_x = pose_res.pose_landmarks.landmark[0].x * w\n",
    "                    shake_buf.append(nose_x)\n",
    "                    if len(shake_buf) == shake_buf.maxlen:\n",
    "                        rms = np.std(shake_buf)\n",
    "                        if rms > SHAKE_RMS_PX:\n",
    "                            shake_start = shake_start or time.time()\n",
    "                        else:\n",
    "                            shake_start = None\n",
    "\n",
    "                        if shake_start and time.time() - shake_start >= SHAKE_SEC:\n",
    "                            drunk = True\n",
    "                else:\n",
    "                    shake_buf.clear()\n",
    "                    shake_start = None\n",
    "\n",
    "                # ================== Send state changes to Arduino and AI Assistant ==================\n",
    "                # Send drowsy state change\n",
    "                if drowsy != last_drowsy:\n",
    "                    if drowsy:\n",
    "                        send_to_arduino(ser, \"ALERT:DROWSY\")\n",
    "                        send_to_assistant(\"DROWSY\", True)\n",
    "                    else:\n",
    "                        send_to_arduino(ser, \"CLEAR:DROWSY\")\n",
    "                        send_to_assistant(\"DROWSY\", False)\n",
    "                last_drowsy = drowsy\n",
    "                \n",
    "                # Send drunk/unwell state change\n",
    "                if drunk != last_drunk:\n",
    "                    if drunk:\n",
    "                        send_to_arduino(ser, \"ALERT:DRUNK\")\n",
    "                        send_to_assistant(\"DRUNK\", True)\n",
    "                    else:\n",
    "                        send_to_arduino(ser, \"CLEAR:DRUNK\")\n",
    "                        send_to_assistant(\"DRUNK\", False)\n",
    "                last_drunk = drunk\n",
    "                \n",
    "                # Send stress state change\n",
    "                if stressed != last_stressed:\n",
    "                    if stressed:\n",
    "                        send_to_arduino(ser, \"ALERT:STRESS\")\n",
    "                        send_to_assistant(\"STRESS\", True)\n",
    "                    else:\n",
    "                        send_to_arduino(ser, \"CLEAR:STRESS\")\n",
    "                        send_to_assistant(\"STRESS\", False)\n",
    "                last_stressed = stressed\n",
    "\n",
    "                # ================== Alerts & UI ==================\n",
    "                alerts = []\n",
    "                if drowsy:\n",
    "                    alerts.append(\"DROWSY\")\n",
    "                if drunk:\n",
    "                    alerts.append(\"DRUNK/UNWELL\")\n",
    "                if stressed:\n",
    "                    alerts.append(\"STRESS\")\n",
    "\n",
    "                for i, txt in enumerate(alerts):\n",
    "                    cv2.putText(frame, txt, (20, 120 + i * 50), \n",
    "                                cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "                if alerts and time.time() - last_beep > 0.8:\n",
    "                    play_beep()\n",
    "                    last_beep = time.time()\n",
    "                    print(*alerts, sep=\" | \")\n",
    "\n",
    "                # Add mic status visual indicator\n",
    "                mic_status = \"MIC ON\" if audio_thread.is_alive() else \"MIC ERROR\"\n",
    "                cv2.putText(frame, mic_status, (w-150, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                            (0, 255, 0) if audio_thread.is_alive() else (0, 0, 255), 2)\n",
    "                \n",
    "                # Add Arduino status indicator\n",
    "                arduino_status = \"ARDUINO ON\" if (ser and ser.is_open) else \"ARDUINO OFF\"\n",
    "                cv2.putText(frame, arduino_status, (w-150, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                            (0, 255, 0) if (ser and ser.is_open) else (0, 0, 255), 2)\n",
    "\n",
    "                # Add Assistant status indicator\n",
    "                try:\n",
    "                    # Quick ping to check if assistant is reachable\n",
    "                    requests.get(ASSISTANT_URL.split('/alert')[0], timeout=0.1)\n",
    "                    asst_status = \"ASSISTANT ON\"\n",
    "                    asst_color = (0, 255, 0)\n",
    "                except:\n",
    "                    asst_status = \"ASSISTANT OFF\"\n",
    "                    asst_color = (0, 0, 255)\n",
    "                    \n",
    "                cv2.putText(frame, asst_status, (w-150, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, asst_color, 2)\n",
    "\n",
    "                # ================== Key handling & display ==================\n",
    "                cv2.imshow(\"Driver Safety Suite\", frame)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord(' '):\n",
    "                    if blob:\n",
    "                        cx0 = blob[0]\n",
    "                        consecutive_lr = 0\n",
    "                        print(\"Steering centre calibrated at\", cx0)\n",
    "                        send_to_arduino(ser, \"SYSTEM:CALIBRATED\")\n",
    "                        send_to_assistant(\"SYSTEM\", True, {\"message\": \"CALIBRATED\"})\n",
    "                    else:\n",
    "                        print(\"No sticker detected for calibration\")\n",
    "                elif key == ord('s'):  # Force stress test\n",
    "                    trigger_stress()\n",
    "                    print(\"Stress manually triggered\")\n",
    "                elif key == ord('b'):  # Test beep\n",
    "                    play_beep()\n",
    "                    print(\"Beep test\")\n",
    "                elif key == ord('c'):  # Test crash alert\n",
    "                    print(\"Crash alert test\")\n",
    "                    send_to_assistant(\"CRASH\", True)\n",
    "                elif key == ord('q'):\n",
    "                    # Send shutdown message to Arduino and assistant\n",
    "                    send_to_arduino(ser, \"SYSTEM:SHUTDOWN\")\n",
    "                    send_to_assistant(\"SYSTEM\", False, {\"message\": \"SHUTDOWN\"})\n",
    "                    break\n",
    "\n",
    "        # Clean up\n",
    "        if ser and ser.is_open:\n",
    "            ser.close()\n",
    "            print(\"[ARDUINO] Connection closed\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
